{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задачи:\n",
    "\n",
    "- ~~Извлекать статьи по ключевым словам;~~\n",
    "- ~~Суммаризировать каждую статью;~~\n",
    "- Суммаризация подходов из статей;\n",
    "- Рерайтинг запроса;\n",
    "- Статья в виде json;\n",
    "- Выбор подходящей LLM;\n",
    "- Разработка веб-интерфейса;\n",
    "- *Попробовать RAPTOR для суммаризации (https://arxiv.org/html/2401.18059v1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import OpenAI, LLMAgent\n",
    "from langchain.agents import initialize_agent, tool\n",
    "from langchain.agents import AgentExecutor, create_gigachat_functions_agent\n",
    "from langchain.chat_models.gigachat import GigaChat\n",
    "import arxiv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GigaChat(credentials=os.environ.get(\"SB_AUTH_DATA\"),\n",
    "                model=\"GigaChat\", timeout=30, verify_ssl_certs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инструмент поиска на Arxiv\n",
    "@tool(\"ArxivSearch\") # name=\"arxiv_search\", description=\"\"\n",
    "def arxiv_search_tool(query: str, max_results: int = 2):\n",
    "    \"\"\"Search articles on Arxiv by keywords\"\"\"\n",
    "    search = arxiv.Search(\n",
    "        query=query,\n",
    "        max_results=max_results,\n",
    "        sort_by=arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "    articles = []\n",
    "    for result in search.results():\n",
    "        articles.append({\n",
    "            \"title\": result.title,\n",
    "            \"summary\": result.summary,\n",
    "            \"url\": result.entry_id\n",
    "        })\n",
    "    return articles\n",
    "\n",
    "# Инструмент суммаризации текста\n",
    "@tool(\"SummarizingTool\") # name=\"summarize_tool\", description=\"Summarizes text using a language model\"\n",
    "def summarize_tool(text: str):\n",
    "    \"\"\"Summarizes text using a language model\"\"\"\n",
    "    prompt = f\"Summarize the following article: {text}\"\n",
    "    summary = llm(prompt)\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация агента с инструментами\n",
    "tools = [arxiv_search_tool, summarize_tool]\n",
    "# agent = initialize_agent(\n",
    "#     tools=tools,\n",
    "#     llm=llm,\n",
    "#     # agent=LLMAgent(name=\"ArxivSummarizerAgent\")\n",
    "# )\n",
    "agent = create_gigachat_functions_agent(llm, tools)\n",
    "executor = AgentExecutor(agent=agent, tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\koltu\\AppData\\Local\\Temp\\ipykernel_29732\\724633227.py:11: DeprecationWarning: The 'Search.results' method is deprecated, use 'Client.results' instead\n",
      "  for result in search.results():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Summarize articles about attention', 'output': 'Articles about attention often highlight the importance of attention mechanisms in visual question answering (VQA) tasks. They discuss how these mechanisms help models focus on relevant areas of images and textual information, leading to improved performance. One article proposes a method to generate human-like attention maps using a Human Attention Network (HAN) trained on the VQA-HAT dataset. Another article introduces Agent Attention, a novel attention paradigm that balances computational efficiency and representation power by introducing agent tokens to the attention module. This new approach is shown to integrate the benefits of Softmax attention and linear attention, offering significant efficiency gains without sacrificing expressiveness. Both articles present promising directions for improving attention mechanisms in VQA and other vision tasks.'}\n"
     ]
    }
   ],
   "source": [
    "# Пример использования агента\n",
    "def search_and_summarize_arxiv(query):\n",
    "    articles = executor({\"input\": query})\n",
    "    return articles\n",
    "\n",
    "# Запуск\n",
    "query = \"Summarize articles about attention\"\n",
    "result = search_and_summarize_arxiv(query)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles about attention often highlight the importance of attention mechanisms in visual question answering (VQA) tasks. They discuss how these mechanisms help models focus on relevant areas of images and textual information, leading to improved performance. One article proposes a method to generate human-like attention maps using a Human Attention Network (HAN) trained on the VQA-HAT dataset. Another article introduces Agent Attention, a novel attention paradigm that balances computational efficiency and representation power by introducing agent tokens to the attention module. This new approach is shown to integrate the benefits of Softmax attention and linear attention, offering significant efficiency gains without sacrificing expressiveness. Both articles present promising directions for improving attention mechanisms in VQA and other vision tasks.\n"
     ]
    }
   ],
   "source": [
    "print(result['output'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
